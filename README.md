# Multi-LLM Chatbot Agent

A sophisticated chatbot system that orchestrates multiple LLM models using LangGraph for intelligent response synthesis.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontendâ”‚    â”‚  Python Backend â”‚    â”‚  LangGraph Core â”‚
â”‚                 â”‚â—„â”€â”€â–ºâ”‚                 â”‚â—„â”€â”€â–ºâ”‚                 â”‚
â”‚  - Chat UI      â”‚    â”‚  - FastAPI      â”‚    â”‚  - Workflow     â”‚
â”‚  - State Mgmt   â”‚    â”‚  - WebSocket    â”‚    â”‚  - Node Graph   â”‚
â”‚  - Real-time    â”‚    â”‚  - Auth         â”‚    â”‚  - LLM Routing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â”‚                       â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Ollama Models â”‚    â”‚  Response       â”‚
                       â”‚                 â”‚    â”‚  Synthesis      â”‚
                       â”‚  - Model 1      â”‚    â”‚                 â”‚
                       â”‚  - Model 2      â”‚â”€â”€â”€â–ºâ”‚  - Combine      â”‚
                       â”‚  - Model 3      â”‚    â”‚  - Refine       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Technology Stack

### Frontend
- **React 18** - Modern UI framework with hooks
- **TypeScript** - Type-safe development
- **Tailwind CSS** - Utility-first styling
- **React Query** - Server state management
- **WebSocket** - Real-time communication

### Backend
- **Python 3.11+** - Core backend language
- **FastAPI** - High-performance async web framework
- **Pydantic** - Data validation and serialization
- **WebSocket** - Real-time bidirectional communication
- **SQLAlchemy** - Database ORM (if needed)

### AI/ML Layer
- **LangGraph** - Multi-LLM orchestration and workflow management
- **Ollama** - CPU-optimized local LLM inference
- **Custom Workflows** - Intelligent routing and synthesis

## ğŸš€ Core Workflow

1. **User Input** â†’ React frontend captures user query
2. **Backend Processing** â†’ Python backend receives and validates request
3. **LLM Orchestration** â†’ LangGraph routes query to two specialized LLM models
4. **Parallel Processing** â†’ Both models process query simultaneously
5. **Response Synthesis** â†’ Third LLM combines and refines responses
6. **Final Output** â†’ Synthesized response returned to user

## ğŸ“ Project Structure

```
â”œâ”€â”€ frontend/                 # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ hooks/          # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ services/       # API communication
â”‚   â”‚   â”œâ”€â”€ types/          # TypeScript definitions
â”‚   â”‚   â””â”€â”€ utils/          # Helper functions
â”‚   â”œâ”€â”€ public/             # Static assets
â”‚   â””â”€â”€ package.json        # Dependencies
â”‚
â”œâ”€â”€ backend/                 # Python backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/            # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ core/           # Configuration and settings
â”‚   â”‚   â”œâ”€â”€ models/         # Data models
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”‚   â””â”€â”€ utils/          # Helper functions
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ main.py            # Application entry point
â”‚
â”œâ”€â”€ langgraph/              # LangGraph workflows
â”‚   â”œâ”€â”€ workflows/          # LLM orchestration flows
â”‚   â”œâ”€â”€ nodes/             # Individual workflow nodes
â”‚   â””â”€â”€ config/            # Model configurations
â”‚
â”œâ”€â”€ docker/                 # Containerization
â”œâ”€â”€ docs/                  # Documentation
â””â”€â”€ README.md              # This file
```

## ğŸ¯ Development Phases

### Phase 1: Foundation Setup
- [ ] Project structure initialization
- [ ] Basic React frontend with chat interface
- [ ] FastAPI backend with WebSocket support
- [ ] Ollama installation and model setup
- [ ] Basic LangGraph workflow structure

### Phase 2: Core LLM Integration
- [ ] Implement two specialized LLM models
- [ ] Create LangGraph workflow for model routing
- [ ] Develop response synthesis logic
- [ ] Basic error handling and fallbacks

### Phase 3: Advanced Features
- [ ] Real-time streaming responses
- [ ] Conversation memory and context
- [ ] Model performance monitoring
- [ ] Advanced error handling and retry logic

### Phase 4: Production Ready
- [ ] Authentication and authorization
- [ ] Rate limiting and security
- [ ] Performance optimization
- [ ] Comprehensive testing
- [ ] Deployment configuration

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+ and npm
- Python 3.11+
- Ollama installed and running
- Docker (optional)

### Quick Start
```bash
# Clone repository
git clone <repository-url>
cd multi-llm-chatbot

# Backend setup
cd backend
pip install -r requirements.txt
uvicorn main:app --reload

# Frontend setup
cd ../frontend
npm install
npm run dev

# Start Ollama models
ollama run llama2
ollama run mistral
ollama run codellama
```

## ğŸ” Key Features

- **Multi-Model Processing**: Leverage different LLM strengths
- **Real-time Responses**: WebSocket-based live communication
- **Intelligent Synthesis**: Smart combination of multiple responses
- **CPU-Optimized**: Local inference with Ollama
- **Scalable Architecture**: Modular design for easy expansion
- **Type Safety**: Full-stack TypeScript and Python typing

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

[Add your license here]

## ğŸ†˜ Support

For questions and support, please open an issue in the repository.
