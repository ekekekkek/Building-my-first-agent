# Multi-LLM Chatbot Agent

A sophisticated chatbot system that orchestrates multiple LLM models using LangGraph for intelligent response synthesis.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontendâ”‚    â”‚  Python Backend â”‚    â”‚  LangGraph Core â”‚
â”‚                 â”‚â—„â”€â”€â–ºâ”‚                 â”‚â—„â”€â”€â–ºâ”‚                 â”‚
â”‚  - Chat UI      â”‚    â”‚  - FastAPI      â”‚    â”‚  - Workflow     â”‚
â”‚  - State Mgmt   â”‚    â”‚  - WebSocket    â”‚    â”‚  - Node Graph   â”‚
â”‚  - Real-time    â”‚    â”‚  - Auth         â”‚    â”‚  - LLM Routing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â”‚                       â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Ollama Models â”‚    â”‚  Response       â”‚
                       â”‚                 â”‚    â”‚  Synthesis      â”‚
                       â”‚                 â”‚    â”‚                 â”‚
                       â”‚  Router         â”‚â”€â”€â”€â–ºâ”‚  Aggregator    â”‚
                       â”‚  (mistral:7b)   â”‚    â”‚  (mistral:7b)  â”‚
                       â”‚                 â”‚    â”‚                 â”‚
                       â”‚  Expert A       â”‚    â”‚  - Combine      â”‚
                       â”‚  (finance-llama)â”‚    â”‚  - Refine       â”‚
                       â”‚                 â”‚    â”‚  - Structure    â”‚
                       â”‚  Expert B       â”‚    â”‚                 â”‚
                       â”‚  (llama3.1:8b)  â”‚    â”‚                 â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Technology Stack

### Frontend
- **React 18** - Modern UI framework with hooks
- **TypeScript** - Type-safe development
- **Tailwind CSS** - Utility-first styling
- **React Query** - Server state management
- **WebSocket** - Real-time communication

### Backend
- **Python 3.11+** - Core backend language
- **FastAPI** - High-performance async web framework
- **Pydantic** - Data validation and serialization
- **WebSocket** - Real-time bidirectional communication
- **SQLAlchemy** - Database ORM (if needed)

### AI/ML Layer
- **LangGraph** - Multi-LLM orchestration and workflow management
- **Ollama** - CPU-optimized local LLM inference
- **Custom Workflows** - Intelligent routing and synthesis

## ğŸš€ Core Workflow

1. **User Input** â†’ React frontend captures user query
2. **Backend Processing** â†’ Python backend receives and validates request
3. **Router Decision** â†’ mistral:7b analyzes query and routes to appropriate expert(s)
4. **Expert Processing** â†’ Specialized models process query in parallel:
   - **Expert A** (finance-llama-8b): Handles finance fundamentals, sentiment, sector context
   - **Expert B** (llama3.1:8b): Manages mathematical reasoning, coding snippets, explanations
5. **Response Aggregation** â†’ mistral:7b combines expert responses into structured answer
6. **Final Output** â†’ Synthesized, coherent response returned to user

## ğŸ§  Model Architecture

### Router (mistral:7b)
- **Purpose**: Query classification and routing
- **Function**: Determines if query is "finance-specific" vs "general"
- **Speed**: Fast inference for quick routing decisions
- **Output**: Routing decision to appropriate expert(s)

### Expert A (martain7r/finance-llama-8b)
- **Specialization**: Finance domain expertise
- **Capabilities**: 
  - Financial fundamentals and concepts
  - Market sentiment analysis
  - Sector-specific context and insights
  - Investment terminology and explanations
- **Use Cases**: Stock analysis, market trends, financial planning

### Expert B (llama3.1:8b)
- **Specialization**: General reasoning and technical tasks
- **Capabilities**:
  - Mathematical reasoning and calculations
  - Code generation (especially pandas, data analysis)
  - Logical explanations and step-by-step reasoning
  - General knowledge and problem-solving
- **Use Cases**: Data analysis, coding help, mathematical problems

### Aggregator (mistral:7b)
- **Purpose**: Response synthesis and refinement
- **Function**: Combines expert outputs into coherent, structured answer
- **Capabilities**:
  - Eliminates redundancy and contradictions
  - Ensures logical flow and consistency
  - Formats response for optimal user experience
  - Maintains context and relevance

## ğŸ“ Project Structure

```
â”œâ”€â”€ frontend/                 # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ hooks/          # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ services/       # API communication
â”‚   â”‚   â”œâ”€â”€ types/          # TypeScript definitions
â”‚   â”‚   â””â”€â”€ utils/          # Helper functions
â”‚   â”œâ”€â”€ public/             # Static assets
â”‚   â””â”€â”€ package.json        # Dependencies
â”‚
â”œâ”€â”€ backend/                 # Python backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/            # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ core/           # Configuration and settings
â”‚   â”‚   â”œâ”€â”€ models/         # Data models
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”‚   â””â”€â”€ utils/          # Helper functions
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ main.py            # Application entry point
â”‚
â”œâ”€â”€ langgraph/              # LangGraph workflows
â”‚   â”œâ”€â”€ workflows/          # LLM orchestration flows
â”‚   â”œâ”€â”€ nodes/             # Individual workflow nodes
â”‚   â””â”€â”€ config/            # Model configurations
â”‚
â”œâ”€â”€ docker/                 # Containerization
â”œâ”€â”€ docs/                  # Documentation
â””â”€â”€ README.md              # This file
```

## ğŸ¯ Development Phases

### Phase 1: Foundation Setup
- [ ] Project structure initialization
- [ ] Basic React frontend with chat interface
- [ ] FastAPI backend with WebSocket support
- [ ] Ollama installation and model setup
- [ ] Basic LangGraph workflow structure

### Phase 2: Core LLM Integration
- [ ] Implement two specialized LLM models
- [ ] Create LangGraph workflow for model routing
- [ ] Develop response synthesis logic
- [ ] Basic error handling and fallbacks

### Phase 3: Advanced Features
- [ ] Real-time streaming responses
- [ ] Conversation memory and context
- [ ] Model performance monitoring
- [ ] Advanced error handling and retry logic

### Phase 4: Production Ready
- [ ] Authentication and authorization
- [ ] Rate limiting and security
- [ ] Performance optimization
- [ ] Comprehensive testing
- [ ] Deployment configuration

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+ and npm
- Python 3.11+
- Ollama installed and running
- Docker (optional)

### Quick Start
```bash
# Clone repository
git clone <repository-url>
cd multi-llm-chatbot

# Backend setup
cd backend
pip install -r requirements.txt
uvicorn main:app --reload

# Frontend setup
cd ../frontend
npm install
npm run dev

# Start Ollama models
ollama run mistral:7b          # Router and Aggregator
ollama run martain7r/finance-llama-8b  # Expert A (Finance)
ollama run llama3.1:8b         # Expert B (General/Technical)
```

## ğŸ” Key Features

- **Multi-Model Processing**: Leverage different LLM strengths
- **Real-time Responses**: WebSocket-based live communication
- **Intelligent Synthesis**: Smart combination of multiple responses
- **CPU-Optimized**: Local inference with Ollama
- **Scalable Architecture**: Modular design for easy expansion
- **Type Safety**: Full-stack TypeScript and Python typing

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

[Add your license here]

## ğŸ†˜ Support

For questions and support, please open an issue in the repository.
